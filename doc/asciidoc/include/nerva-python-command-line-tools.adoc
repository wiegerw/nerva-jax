include::../settings.adoc[]

== Command line tools
The following command line tools are available. They can be found in the `tools` directory.

|===
|Tool |Description

|`{mlptool}`
|A tool for training multilayer perceptrons.

|`inspect_npz.py`
|A tool for inspecting the contents of a file in NumPy NPZ format.
|===

=== The tool {mlptool}
The tool `{mlptool}` can be used for training multilayer perceptrons. An example invocation of the `{mlptool}` tool is

[.small-code]
[source,bash]
----
include::../../../examples/train_cifar10_cli.sh[tag=doc]
----
This will train a https://www.cs.toronto.edu/~kriz/cifar.html[CIFAR-10] model using an MLP consisting of three linear layers with activation functions ReLU, ReLU and no activation. A script `prepare_data.py` is available in the `data` directory
that can be used to download the dataset, flatten it and store it in `.npz` format. See the section <<preparing-data>> for details.

The output may look like this:
[[mlp_output]]
[.small-code]
[source]
----
Loading dataset from file ../../data/cifar10-flattened.npz
=== Nerva python model ===
MultilayerPerceptron(
  Dense(output_size=1024, activation=ReLU(), optimizer=Nesterov(0.9), weight_initializer=Xavier, dropout=0.0),
  Dense(output_size=1024, activation=ReLU(), optimizer=Nesterov(0.9), weight_initializer=Xavier, dropout=0.0),
  Dense(output_size=10, activation=NoActivation(), optimizer=Nesterov(0.9), weight_initializer=Xavier, dropout=0.0)
)
loss = SoftmaxCrossEntropyLoss()
scheduler = 0.01
layer densities: 3145728/3145728 (100%), 1048576/1048576 (100%), 10240/10240 (100%)


=== Training Nerva model ===
epoch   0  lr: 0.01000000  loss: 2.30489253  train accuracy: 0.09768000  test accuracy: 0.09770000  time: 0.00000000s
epoch   1  lr: 0.01000000  loss: 1.67161558  train accuracy: 0.40710000  test accuracy: 0.40870000  time: 14.79412249s
epoch   2  lr: 0.01000000  loss: 1.57473959  train accuracy: 0.44548000  test accuracy: 0.44260000  time: 14.33901316s
epoch   3  lr: 0.01000000  loss: 1.48164101  train accuracy: 0.47662000  test accuracy: 0.46680000  time: 14.62393199s
epoch   4  lr: 0.01000000  loss: 1.40226001  train accuracy: 0.50328000  test accuracy: 0.48750000  time: 15.14273496s
epoch   5  lr: 0.01000000  loss: 1.35031182  train accuracy: 0.52174000  test accuracy: 0.49900000  time: 15.16651454s
epoch   6  lr: 0.01000000  loss: 1.31527882  train accuracy: 0.53150000  test accuracy: 0.50410000  time: 15.02228177s
epoch   7  lr: 0.01000000  loss: 1.27560615  train accuracy: 0.54598000  test accuracy: 0.51150000  time: 14.99119695s
epoch   8  lr: 0.01000000  loss: 1.24606835  train accuracy: 0.55446000  test accuracy: 0.51660000  time: 14.84064179s
epoch   9  lr: 0.01000000  loss: 1.21105695  train accuracy: 0.56862000  test accuracy: 0.52180000  time: 14.82885451s
epoch  10  lr: 0.01000000  loss: 1.19145860  train accuracy: 0.57378000  test accuracy: 0.52410000  time: 15.87854538s
----

include::command-line-tools.adoc[tags=mlptool-options]

include::command-line-tools.adoc[tags=general-options]

include::command-line-tools.adoc[tags=random-generator-options]

include::command-line-tools.adoc[tags=layer-configuration-options]

include::command-line-tools.adoc[tags=training-configuration-options]

include::command-line-tools.adoc[tags=dataset-options]

include::inspect-npz.adoc[]
