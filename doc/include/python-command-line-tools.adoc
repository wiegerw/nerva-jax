== Command line tools
The tool `mlp.py` can be used to do training experiments with multilayer perceptrons.

=== The tool mlp.py
An example invocation of the `mlp.py` tool is

[source]
----
include::../../python/examples/cifar10.sh[tag=doc]
----
This will train a CIFAR-10 model using an MLP consisting of three layers with activation functions ReLU, ReLU and no activation. Note that it automatically downloads the CIFAR-10 dataset in the folder `../data` if it doesn't yet exist.

The output may look like this:
[.small-code]
[source]
----
Loading dataset from file ../../data/cifar10-flattened.npz
=== Nerva python model ===
MultilayerPerceptron(
  Dense(output_size=1024, activation=ReLU(), optimizer=Nesterov(0.9), weight_initializer=Xavier, dropout=0.0),
  Dense(output_size=1024, activation=ReLU(), optimizer=Nesterov(0.9), weight_initializer=Xavier, dropout=0.0),
  Dense(output_size=10, activation=NoActivation(), optimizer=Nesterov(0.9), weight_initializer=Xavier, dropout=0.0)
)
loss = SoftmaxCrossEntropyLoss()
scheduler = 0.01
layer densities: 3145728/3145728 (100%), 1048576/1048576 (100%), 10240/10240 (100%)


=== Training Nerva model ===
epoch   0  lr: 0.01000000  loss: 2.30489253  train accuracy: 0.09768000  test accuracy: 0.09770000  time: 0.00000000s
epoch   1  lr: 0.01000000  loss: 1.67161558  train accuracy: 0.40710000  test accuracy: 0.40870000  time: 14.79412249s
epoch   2  lr: 0.01000000  loss: 1.57473959  train accuracy: 0.44548000  test accuracy: 0.44260000  time: 14.33901316s
epoch   3  lr: 0.01000000  loss: 1.48164101  train accuracy: 0.47662000  test accuracy: 0.46680000  time: 14.62393199s
epoch   4  lr: 0.01000000  loss: 1.40226001  train accuracy: 0.50328000  test accuracy: 0.48750000  time: 15.14273496s
epoch   5  lr: 0.01000000  loss: 1.35031182  train accuracy: 0.52174000  test accuracy: 0.49900000  time: 15.16651454s
epoch   6  lr: 0.01000000  loss: 1.31527882  train accuracy: 0.53150000  test accuracy: 0.50410000  time: 15.02228177s
epoch   7  lr: 0.01000000  loss: 1.27560615  train accuracy: 0.54598000  test accuracy: 0.51150000  time: 14.99119695s
epoch   8  lr: 0.01000000  loss: 1.24606835  train accuracy: 0.55446000  test accuracy: 0.51660000  time: 14.84064179s
epoch   9  lr: 0.01000000  loss: 1.21105695  train accuracy: 0.56862000  test accuracy: 0.52180000  time: 14.82885451s
epoch  10  lr: 0.01000000  loss: 1.19145860  train accuracy: 0.57378000  test accuracy: 0.52410000  time: 15.87854538s
----

include::command-line-tools.adoc[tags=mlptool-options]

include::command-line-tools.adoc[tags=general-options]

include::command-line-tools.adoc[tags=random-generator-options]

include::command-line-tools.adoc[tags=layer-configuration-options]

include::command-line-tools.adoc[tags=training-configuration-options]

include::command-line-tools.adoc[tags=dataset-options]

ifdef::nerva-python[]
include::command-line-tools.adoc[tags=pruning-options]

include::command-line-tools.adoc[tags=computation-options]

include::command-line-tools.adoc[tags=miscellaneous-options]
endif::nerva-python[]
